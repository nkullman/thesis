\section{General Discussion \& Conclusion}
% We did good
We used a case study of the impact of climate change on the joint provision of forest ecosystem services to successfully demonstrate the utility of a new measure of pairwise objective conflict and to demonstrate a new application of existing conflict measures in the quantification of conflict within and among multi-objective systems.

% We did good in something that was hard to do good in
We argue that the case study served as a rigorous first test of the process and the conflict measures, because there was little overall conflict in these systems and the differences in relative objective achievement across climate scenarios were not great. For instance, in the case study, the hypervolume for each climate scenario was relatively large, with solutions occupying over 80\% of the objective space in all cases. In addition, in all but one pairwise objective comparison, it was difficult to discern any distinct conflict relationship between the objectives. As a result, our proposed conflict metric and the hypervolume indicators were required to detect subtle differences in conflict, which they did successfully. Should the differences in objective achievement between climate scenarios have been more pronounced, or should the objectives have been in greater conflict with one another, we suspect the utility of these measures and the process we demonstrated here would only increase.

% But who's to say that it will always do good. It may not. You'd want to also consider other scenarios, like this food processing one
Of course, our success here is not a guarantee of future success. In consideration of different climate change scenarios, different ecosystem services, or a different study area, the conflict measures may prove less useful. The application of this quantitative conflict analysis should also be tested in other multi-objective systems.

Consider again the manager of the food processing facility, this time with looming regulatory changes on the horizon, such as a change in the maximum allowable microbiological levels. For each of a number of such levels, the manager may consider the balance in processing time and nutrient retention. Would the hypervolumes always report greater joint objective provision under larger allowable levels? Or in the case of the manager overseeing multiple hospitals, how does the pairwise conflict between operating cost and patient throughput vary between them?

% We think our thing would continue to do good, bc, again, it did good here. It was so great.
Based off our results, we believe that our new conflict measure and the process we suggest would be useful to the managers in these cases as well. As we saw, the proposed conflict measure was successful in being able to identify which objective pairs were most in conflict. We also saw that the hypervolumes were successful in detecting increasing system-level conflict under different environmental conditions. These variations in conflict were supported by the underlying model data. 

% But it's not perfect, you know?
However, the new conflict metric and process are not without shortcomings. We first note that $C_{ij}$ is susceptible to relatively large variations in cases where neither the distance component $c_{ij,d}$ nor the rank correlation component $c_{ij,\rho}$ tend toward their $[0,1]$ bounds. In these cases, the components have more influence on the value of the conflict metric $C_{ij}$, so slight variations can lead to relatively large differences. In addition, differences in system conflict cannot be totally explained by the collection of pairwise conflict measures. For instance, while the small pairwise conflict metrics in the case study ($< 0.4$) coarsely correspond to large hypervolumes ($> 0.8$), we cannot use them to explain the source of the small differences in hypervolume. Indeed, we saw that for the climate scenario with the most system conflict, E85, the sum of its pairwise conflict metrics was smallest. Lastly, the measures used in the proposed process can be difficult to interpret, since they provide results in terms of relative objective achievement. That is, instead of having results that are measurable in the dimensions of your objectives, they are instead in percent achievements for the objectives.

% So we need to do more research, more case studies, and we need to try to make our tool better. But all in all, we're awesome. Over and out.
In summary, we have provided a foundation for quantitative conflict analysis for the comparison of multi-objective systems. Our results show that our proposed process and the new conflict metric are successful in quantifying and differentiating the amount of conflict within and across multi-objective
systems and that they stand to serve as a useful tool for multi-objective decision making. However, more experimentation with the proposed quantitative conflict analysis is required to better understand the limitations of its utility, and refinements to the new pairwise conflict measure should be investigated. Especially useful refinements would be those which address the variation in the conflict metric when neither component tends towards a limiting value of 0 or 1.

which as proven successful in the quantification and differentiation successfully demonstrated that the tool is  useful if they could be especially to address those instances in which its components are in the case where ran correlation and avg distance to ideal are both mid-range.